{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "This notebook contains experiment results from the paper, [Deep Multi-Task Learning for SSVEP Detection and Visual Response Mapping](https://jinglescode.github.io/ssvep-multi-task-learning/). Using multi-task learning to capture signals simultaneously from the fovea efficiently and the neighboring targets in the peripheral vision generate a visual response map. A calibration-free user-independent solution, desirable for clinical diagnostics. A stepping stone for an objective assessment of glaucoma patientsâ€™ visual field.\n",
    "\n",
    "![figures-main-idea-big](https://user-images.githubusercontent.com/1694368/91680983-9caa4580-eb7f-11ea-8bfd-50e0705c141d.jpg)\n",
    "\n",
    "## torchsignal\n",
    "\n",
    "This notebook uses [torchsignal](https://github.com/jinglescode/torchsignal), a package for common signal processing tasks for PyTorch. Use Git or checkout with SVN, and install the dependencies:\n",
    "\n",
    "```\n",
    "git clone https://github.com/jinglescode/torchsignal.git\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We used an open-access dataset by Tsinghua University, HS-SSVEP, a 40-classes dataset for visual spelling tasks.\n",
    "This dataset is by Yijun Wang, Xiaogang Chen, Xiaorong Gao, Shangkai Gao\n",
    "\n",
    "[[Paper]((https://ieeexplore.ieee.org/document/7740878))] [[Dataset website](http://bci.med.tsinghua.edu.cn/download.html)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: '..\\\\torchsignal'\n",
      "C:\\Users\\abdul\\Downloads\\review3-code\n"
     ]
    }
   ],
   "source": [
    "%cd ..\\torchsignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\Downloads\\review3-code\\torchsignal\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\abdul\\Downloads\\review3-code\\torchsignal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\abdul\\anaconda3\\lib\\site-packages (1.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsignal.datasets.hsssvep import HSSSVEP\n",
    "from torchsignal.datasets.multiplesubjects import MultipleSubjects\n",
    "from torchsignal.trainer.multitask import Multitask_Trainer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "  \"exp_name\": \"model\",\n",
    "  \"seed\": 12,\n",
    "  \"segment_config\": {\n",
    "    \"window_len\": 4,\n",
    "    \"shift_len\": 250,\n",
    "    \"sample_rate\": 250,\n",
    "    \"add_segment_axis\": True\n",
    "  },\n",
    "  \"bandpass_config\": {\n",
    "      \"sample_rate\": 250,\n",
    "      \"lowcut\": 1,\n",
    "      \"highcut\": 40,\n",
    "      \"order\": 6\n",
    "  },\n",
    "  \"train_subject_ids\": {\n",
    "    \"low\": 1,\n",
    "    \"high\": 35\n",
    "  },\n",
    "  \"test_subject_ids\": {\n",
    "    \"low\": 1,\n",
    "    \"high\": 35\n",
    "  },\n",
    "  \"root\": \"C:/Users/abdul/Downloads/review3-code/hssvep\",\n",
    "  \"selected_channels\": ['PZ', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'O1', 'Oz', 'O2', 'PO7', 'PO8'],\n",
    "  \"num_classes\": 40,\n",
    "  \"num_channel\": 11,\n",
    "  \"batchsize\": 64,\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 100,\n",
    "  \"patience\": 5,\n",
    "  \"early_stopping\": 10,\n",
    "  \"model\": {\n",
    "    \"n1\": 4,\n",
    "    \"kernel_window_ssvep\": 59,\n",
    "    \"kernel_window\": 19,\n",
    "    \"conv_3_dilation\": 4,\n",
    "    \"conv_4_dilation\": 4\n",
    "  },\n",
    "  \"gpu\": 0,\n",
    "  \"multitask\": True,\n",
    "  \"runkfold\": 3,\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:\"+str(config['gpu']) if torch.cuda.is_available() else \"cpu\")\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Subjects Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load subject: 1\n",
      "Load subject: 2\n",
      "Load subject: 3\n",
      "Load subject: 4\n",
      "Load subject: 5\n",
      "Load subject: 6\n",
      "Load subject: 7\n",
      "Load subject: 8\n",
      "Load subject: 9\n",
      "Load subject: 10\n",
      "Load subject: 11\n",
      "Load subject: 12\n",
      "Load subject: 13\n",
      "Load subject: 14\n",
      "Load subject: 15\n",
      "Load subject: 16\n",
      "Load subject: 17\n",
      "Load subject: 18\n",
      "Load subject: 19\n",
      "Load subject: 20\n",
      "Load subject: 21\n",
      "Load subject: 22\n",
      "Load subject: 23\n",
      "Load subject: 24\n",
      "Load subject: 25\n",
      "Load subject: 26\n",
      "Load subject: 27\n",
      "Load subject: 28\n",
      "Load subject: 29\n",
      "Load subject: 30\n",
      "Load subject: 31\n",
      "Load subject: 32\n",
      "Load subject: 33\n",
      "Load subject: 34\n",
      "Load subject: 35\n"
     ]
    }
   ],
   "source": [
    "subject_ids = list(np.arange(config['train_subject_ids']['low'], config['train_subject_ids']['high']+1, dtype=int))\n",
    "\n",
    "data = MultipleSubjects(\n",
    "    dataset=HSSSVEP, \n",
    "    root=config['root'], \n",
    "    subject_ids=subject_ids, \n",
    "    selected_channels=config['selected_channels'],\n",
    "    segment_config=config['segment_config'],\n",
    "    bandpass_config=config['bandpass_config'],\n",
    "    one_hot_labels=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (240, 11, 1000)\n",
      "Target shape: (240,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input data shape:\", data.data_by_subjects[1].data.shape)\n",
    "print(\"Target shape:\", data.data_by_subjects[1].targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-task Learning Model\n",
    "\n",
    "![figures-model](https://user-images.githubusercontent.com/1694368/91679200-2ce58c00-eb7a-11ea-82a3-1df6ef6aee24.png)\n",
    "\n",
    "![figures-mtl-module](https://user-images.githubusercontent.com/1694368/91679765-cb262180-eb7b-11ea-9417-64af2d3f0292.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multitask_Model(nn.Module):\n",
    "    def __init__(self, num_channel=10, num_classes=4, signal_length=1000, filters_n1=4, kernel_window_ssvep=59, kernel_window=19, conv_3_dilation=4, conv_4_dilation=4):\n",
    "        super().__init__()\n",
    "\n",
    "        filters = [filters_n1, filters_n1 * 2]\n",
    "\n",
    "        self.conv_1 = conv_block(in_ch=1, out_ch=filters[0], kernel_size=(1, kernel_window_ssvep), w_in=signal_length)\n",
    "        self.conv_2 = conv_block(in_ch=filters[0], out_ch=filters[0], kernel_size=(num_channel, 1))\n",
    "        self.conv_3 = conv_block(in_ch=filters[0], out_ch=filters[1], kernel_size=(1, kernel_window), padding=(0,conv_3_dilation-1), dilation=(1,conv_3_dilation), w_in=self.conv_1.w_out)\n",
    "        self.conv_4 = conv_block(in_ch=filters[1], out_ch=filters[1], kernel_size=(1, kernel_window), padding=(0,conv_4_dilation-1), dilation=(1,conv_4_dilation), w_in=self.conv_3.w_out)\n",
    "        self.conv_mtl = multitask_block(filters[1]*num_classes, num_classes, kernel_size=(1, self.conv_4.w_out))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x,1)\n",
    "\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv_3(x)\n",
    "        x = self.conv_4(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv_mtl(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, padding=(0,0), dilation=(1,1), groups=1, w_in=None):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, dilation=dilation, groups=groups),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ELU(inplace=True)\n",
    "        )\n",
    "\n",
    "        if w_in is not None:\n",
    "            self.w_out = int( ((w_in + 2 * padding[1] - dilation[1] * (kernel_size[1]-1)-1) / 1) + 1 )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "    \n",
    "class multitask_block(nn.Module):\n",
    "    def __init__(self, in_ch, num_classes, kernel_size):\n",
    "        super(multitask_block, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv_mtl = nn.Conv2d(in_ch, num_classes*2, kernel_size=kernel_size, groups=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat(self.num_classes*[x], 1)\n",
    "        x = self.conv_mtl(x)\n",
    "        x = x.squeeze()\n",
    "        x = x.view(-1, self.num_classes, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([40, 11, 1000])\n",
      "Output shape: torch.Size([40, 40, 2])\n",
      "Model size: 520788\n"
     ]
    }
   ],
   "source": [
    "model = Multitask_Model(num_channel=config['num_channel'],\n",
    "    num_classes=config['num_classes'],\n",
    "    signal_length=config['segment_config']['window_len'] * config['bandpass_config']['sample_rate'],\n",
    "    filters_n1=config['model']['n1'],\n",
    "    kernel_window_ssvep=config['model']['kernel_window_ssvep'],\n",
    "    kernel_window=config['model']['kernel_window'],\n",
    "    conv_3_dilation=config['model']['conv_3_dilation'],\n",
    "    conv_4_dilation=config['model']['conv_4_dilation'],\n",
    ").to(device)\n",
    "\n",
    "x = torch.ones((40, config['num_channel'], config['segment_config']['window_len'] * config['bandpass_config']['sample_rate'])).to(device)\n",
    "print(\"Input shape:\", x.shape)\n",
    "y = model(x)\n",
    "print(\"Output shape:\", y.shape)\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Model size:', count_params(model))\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-09d5af75cc80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultitask_Trainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_classes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultitask_learning\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopk_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\review3-code\\torchsignal\\trainer\\multitask.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataloaders_dict, num_epochs, early_stopping, topk_accuracy, min_num_epoch, save_model)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/model.pth'"
     ]
    }
   ],
   "source": [
    "subject_kfold_acc = {}\n",
    "subject_kfold_f1 = {}\n",
    "\n",
    "test_subject_ids = list(np.arange(config['test_subject_ids']['low'], config['test_subject_ids']['high']+1, dtype=int))\n",
    "\n",
    "for subject_id in test_subject_ids:\n",
    "    print('Subject', subject_id)\n",
    "    kfold_acc = []\n",
    "    kfold_f1 = []\n",
    "        \n",
    "    for k in range(config['runkfold']):\n",
    "        data.split_by_kfold(kfold_k=k, kfold_split=config['runkfold'])\n",
    "        train_loader, val_loader, test_loader = data.leave_one_subject_out(selected_subject_id=subject_id, dataloader_batchsize=config['batchsize'])\n",
    "        dataloaders_dict = {\n",
    "            'train': train_loader,\n",
    "            'val': val_loader\n",
    "        }\n",
    "        \n",
    "        model = Multitask_Model(num_channel=config['num_channel'],\n",
    "            num_classes=config['num_classes'],\n",
    "            signal_length=config['segment_config']['window_len'] * config['bandpass_config']['sample_rate'],\n",
    "            filters_n1=config['model']['n1'],\n",
    "            kernel_window_ssvep=config['model']['kernel_window_ssvep'],\n",
    "            kernel_window=config['model']['kernel_window'],\n",
    "            conv_3_dilation=config['model']['conv_3_dilation'],\n",
    "            conv_4_dilation=config['model']['conv_4_dilation'],\n",
    "        ).to(device)\n",
    "\n",
    "        epochs=config['epochs'] if 'epochs' in config else 50\n",
    "        patience=config['patience'] if 'patience' in config else 20\n",
    "        early_stopping=config['early_stopping'] if 'early_stopping' in config else 40\n",
    "\n",
    "        trainer = Multitask_Trainer(model, model_name=\"model\", device=device, num_classes=config['num_classes'], multitask_learning=True, patience=patience, verbose=False)\n",
    "\n",
    "        trainer.fit(dataloaders_dict, num_epochs=epochs, early_stopping=early_stopping, topk_accuracy=1, save_model=True)\n",
    "        \n",
    "        test_loss, test_acc, test_metric = trainer.validate(test_loader, 1)\n",
    "        print('Testset (k={}) -> loss:{:.5f}, acc:{:.5f}, f1:{:.5f}'.format(k+1, test_loss, test_acc, test_metric))\n",
    "        kfold_acc.append(test_acc)\n",
    "        kfold_f1.append(test_metric)\n",
    "    \n",
    "    subject_kfold_acc[subject_id] = kfold_acc\n",
    "    subject_kfold_f1[subject_id] = kfold_f1\n",
    "    print()\n",
    "\n",
    "print('Results')\n",
    "print('subject_kfold_acc', subject_kfold_acc)\n",
    "print('subject_kfold_f1', subject_kfold_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc\n",
    "subjects = []\n",
    "acc = []\n",
    "acc_min = 1.0\n",
    "acc_max = 0.0\n",
    "\n",
    "for subject_id in subject_kfold_acc:\n",
    "    subjects.append(subject_id)\n",
    "    avg_acc = np.mean(subject_kfold_acc[subject_id])\n",
    "    if avg_acc < acc_min:\n",
    "        acc_min = avg_acc\n",
    "    if avg_acc > acc_max:\n",
    "        acc_max = avg_acc\n",
    "    acc.append(avg_acc)\n",
    "\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(subjects)]\n",
    "figure(num=None, figsize=(15, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.bar(x_pos, acc, color='skyblue')\n",
    "plt.xlabel(\"Subject\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.title(\"Average k-fold Accuracies by subjects\")\n",
    "plt.xticks(x_pos, subjects)\n",
    "plt.ylim([acc_min-0.02, acc_max+0.02])\n",
    "plt.show()\n",
    "\n",
    "# f1\n",
    "subjects = []\n",
    "f1 = []\n",
    "f1_min = 1.0\n",
    "f1_max = 0.0\n",
    "\n",
    "for subject_id in subject_kfold_f1:\n",
    "    subjects.append(subject_id)\n",
    "    avg_f1 = np.mean(subject_kfold_f1[subject_id])\n",
    "    if avg_f1 < f1_min:\n",
    "        f1_min = avg_f1\n",
    "    if avg_f1 > f1_max:\n",
    "        f1_max = avg_f1\n",
    "    f1.append(avg_f1)\n",
    "\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(subjects)]\n",
    "figure(num=None, figsize=(15, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.bar(x_pos, f1, color='skyblue')\n",
    "plt.xlabel(\"Subject\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.title(\"Average k-fold F1 by subjects\")\n",
    "plt.xticks(x_pos, subjects)\n",
    "plt.ylim([f1_min-0.02, f1_max+0.02])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Average acc:', np.mean(acc))\n",
    "print('Average f1:', np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_based_acc = {\n",
    "  1:\t{\"itcca\": 0.92, \"trca\": 0.93, \"cca\": 0.51, \"fbcca\": 0.78},\n",
    "  2:\t{\"itcca\": 0.94, \"trca\": 0.98, \"cca\": 0.7, \"fbcca\": 0.88},\n",
    "  3:\t{\"itcca\": 0.99, \"trca\": 0.99, \"cca\": 0.95, \"fbcca\": 0.98},\n",
    "  4:\t{\"itcca\": 0.97, \"trca\": 0.96, \"cca\": 0.84, \"fbcca\": 0.88},\n",
    "  5:\t{\"itcca\": 0.99, \"trca\": 0.98, \"cca\": 0.71, \"fbcca\": 0.89},\n",
    "  6:\t{\"itcca\": 0.88, \"trca\": 0.9, \"cca\": 0.56, \"fbcca\": 0.74},\n",
    "  7:\t{\"itcca\": 0.89, \"trca\": 0.95, \"cca\": 0.48, \"fbcca\": 0.68},\n",
    "  8:\t{\"itcca\": 0.81, \"trca\": 0.86, \"cca\": 0.37, \"fbcca\": 0.48},\n",
    "  9:\t{\"itcca\": 0.8, \"trca\": 0.78, \"cca\": .56, \"fbcca\": 0.73},\n",
    "  10:\t{\"itcca\": 0.91, \"trca\": 0.9, \"cca\": 0.66, \"fbcca\": 0.76},\n",
    "  11:\t{\"itcca\": 0.54, \"trca\": 0.54, \"cca\": 0.2, \"fbcca\": 0.28},\n",
    "  12:\t{\"itcca\": 0.99, \"trca\": 0.98, \"cca\": 0.9, \"fbcca\": 0.93},\n",
    "  13:\t{\"itcca\": 0.96, \"trca\": 0.95, \"cca\": 0.49, \"fbcca\": 0.68},\n",
    "  14:\t{\"itcca\": 0.99, \"trca\": 0.99, \"cca\": 0.83, \"fbcca\": 0.88},\n",
    "  15:\t{\"itcca\": 0.78, \"trca\": 0.83, \"cca\": 0.41, \"fbcca\": 0.46},\n",
    "  16:\t{\"itcca\": 0.55, \"trca\": 0.74, \"cca\": 0.18, \"fbcca\": 0.55},\n",
    "  17:\t{\"itcca\": 0.9, \"trca\": 0.92, \"cca\": 0.48, \"fbcca\": 0.54},\n",
    "  18:\t{\"itcca\": 0.76, \"trca\": 0.78, \"cca\": 0.46, \"fbcca\": 0.65},\n",
    "  19:\t{\"itcca\": 0.32, \"trca\": 0.37, \"cca\": 0.15, \"fbcca\": 0.25},\n",
    "  20:\t{\"itcca\": 0.95, \"trca\": 0.95, \"cca\": .63, \"fbcca\": 0.87},\n",
    "  21:\t{\"itcca\": 0.83, \"trca\": 0.95, \"cca\": 0.39, \"fbcca\": 0.57},\n",
    "  22:\t{\"itcca\": 0.93, \"trca\": 0.95, \"cca\": 0.68, \"fbcca\": 0.94},\n",
    "  23:\t{\"itcca\": 0.89, \"trca\": 0.88, \"cca\": 0.62, \"fbcca\": 0.9},\n",
    "  24:\t{\"itcca\": 0.95, \"trca\": 0.96, \"cca\": 0.66, \"fbcca\": 0.84},\n",
    "  25:\t{\"itcca\": 0.97, \"trca\": 0.98, \"cca\": 0.86, \"fbcca\": 0.8},\n",
    "  26:\t{\"itcca\": 0.99, \"trca\": 1,\t\"cca\": 0.87, \"fbcca\": 0.83},\n",
    "  27:\t{\"itcca\": 0.98, \"trca\": 1, \"cca\": 0.79, \"fbcca\": 0.88},\n",
    "  28:\t{\"itcca\": 0.92, \"trca\": 0.95, \"cca\": .58, \"fbcca\": 0.9},\n",
    "  29:\t{\"itcca\": 0.6, \"trca\": 0.52, \"cca\": 0.15, \"fbcca\": 0.4},\n",
    "  30:\t{\"itcca\": 0.88, \"trca\": 0.86, \"cca\": 0.6, \"fbcca\": 0.72},\n",
    "  31:\t{\"itcca\": 1, \"trca\": 1, \"cca\": 0.9, \"fbcca\": 0.98},\n",
    "  32:\t{\"itcca\": 1, \"trca\": 1, \"cca\": 0.86, \"fbcca\": 0.92},\n",
    "  33:\t{\"itcca\": 0.36, \"trca\": 0.42, \"cca\": 0.2, \"fbcca\": 0.26},\n",
    "  34:\t{\"itcca\": 0.97, \"trca\": 0.98, \"cca\": 0.8, \"fbcca\": 0.86},\n",
    "  35:\t{\"itcca\": 0.94, \"trca\": 0.93, \"cca\": 0.63, \"fbcca\": 0.57}\n",
    "}\n",
    "\n",
    "fbcca = []\n",
    "trca = []\n",
    "cca = []\n",
    "subjects_id = list(cca_based_acc.keys())\n",
    "\n",
    "for subject in cca_based_acc:\n",
    "    fbcca.append(cca_based_acc[subject][\"fbcca\"])\n",
    "    trca.append(cca_based_acc[subject][\"trca\"])\n",
    "    cca.append(cca_based_acc[subject][\"cca\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(len(subjects_id))  # the x locations for the groups\n",
    "bar_width = 0.25\n",
    "width = 0.25\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 4), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "rects1 = ax.bar(ind - bar_width, acc, width, label='MTL')\n",
    "rects2 = ax.bar(ind, trca, width, label='TRCA')\n",
    "rects3 = ax.bar(ind + bar_width, fbcca, width, label='FBCCA')\n",
    "# rects4 = ax.bar(ind + bar_width*1.5, cca, width, label='CCA')\n",
    "\n",
    "ax.set_xlabel(\"Subject\", fontsize=20)\n",
    "ax.set_ylabel('Accuracies', fontsize=20)\n",
    "# ax.set_title('Compare Accuracies by Methods')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(subjects_id)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
